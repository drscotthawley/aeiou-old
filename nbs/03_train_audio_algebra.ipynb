{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200fed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train_audio_algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f3c7b",
   "metadata": {},
   "source": [
    "# train_audio_algebra\n",
    "\n",
    "> Trying to map audio embeddings to vector spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ecf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from prefigure.prefigure import get_all_args, push_wandb_config\n",
    "from copy import deepcopy\n",
    "import math\n",
    "import json\n",
    "\n",
    "import accelerate\n",
    "import sys\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch import optim, nn\n",
    "from torch import multiprocessing as mp\n",
    "from torch.nn import functional as F\n",
    "#from torch.utils import data\n",
    "from tqdm import tqdm, trange\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "import wandb\n",
    "from shazbot.viz import embeddings_table, pca_point_cloud, audio_spectrogram_image, tokens_spectrogram_image\n",
    "import shazbot.blocks_utils as blocks_utils\n",
    "from shazbot.icebox import load_audio_for_jbx, IceBoxEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDK_DeleteMe(nn.Module):\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        reals = batch[0]  # grab actual audio part of batch, not the filenames\n",
    "\n",
    "        #print(\"reals.size() = \",reals.size())\n",
    "        reals_mono = reals[:,0,:] # mono only, sorry\n",
    "        #print(\"reals_mono.size() = \",reals_mono.size())\n",
    "\n",
    "        encoder_input = audio_for_jbx(reals_mono, device=reals.device)\n",
    "\n",
    "        # Draw uniformly distributed continuous timesteps\n",
    "        t = self.rng.draw(reals.shape[0])[:, 0].to(self.device)\n",
    "\n",
    "        # Calculate the noise schedule parameters for those timesteps\n",
    "        alphas, sigmas = get_alphas_sigmas(get_crash_schedule(t))\n",
    "\n",
    "        # Combine the ground truth images and the noise\n",
    "        alphas = alphas[:, None, None]\n",
    "        sigmas = sigmas[:, None, None]\n",
    "        noise = torch.randn_like(reals)\n",
    "        noised_reals = reals * alphas + noise * sigmas\n",
    "        targets = noise * alphas - reals * sigmas\n",
    "\n",
    "        # Compute the model output and the loss.\n",
    "        with torch.cuda.amp.autocast():\n",
    "            zs = self.encoder(encoder_input) # indices at 3 resolutions\n",
    "            xs = self.vqvae.bottleneck.decode(zs) # vectors vectors at 3 resolutions\n",
    "            tokens = self.package_3layer_tokens(xs).float() # combine resolutions\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            v = self.diffusion(noised_reals, t, tokens)\n",
    "            mse_loss = F.mse_loss(v, targets)\n",
    "            loss = mse_loss\n",
    "\n",
    "        log_dict = {\n",
    "            'train/loss': loss.detach(),\n",
    "            'train/mse_loss': mse_loss.detach(),\n",
    "        }\n",
    "\n",
    "        self.log_dict(log_dict, prog_bar=True, on_step=True)\n",
    "        return loss\n",
    "\n",
    "    def package_3layer_tokens(self, tokens_list):\n",
    "        \"jukebox vqvae returns a list of 3 1-dim tensor. Here we package them...somehow\"\n",
    "        ind = self.jukebox_layers[0]\n",
    "        return tokens_list[ind] # TODO: just grab one set of tokens for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684fb7e1",
   "metadata": {},
   "source": [
    "## The main model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "class AudioAlgebra(nn.Module):\n",
    "    def __init__(self, global_args, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = IceBoxEncoder(global_args)\n",
    "\n",
    "\n",
    "    def loss(self, reals):\n",
    "\n",
    "        if self.pqmf_bands > 1:    \n",
    "            encoder_input = self.pqmf(reals)\n",
    "        else:\n",
    "            encoder_input = reals\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            latents = self.encoder(encoder_input).float()            \n",
    "\n",
    "        loss = 0# TODO: fill in mse_loss + mrstft_loss\n",
    "        \n",
    "        log_dict = {\n",
    "            'train/mse_loss': mse_loss.detach(),\n",
    "            'train/mb_distance': mb_distance.detach(),\n",
    "        }\n",
    "\n",
    "        return loss, log_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41aa594",
   "metadata": {},
   "source": [
    "## Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf15845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def main():\n",
    "\n",
    "    args = get_all_args()\n",
    "    \n",
    "    args.random_crop = False\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    try:\n",
    "        mp.set_start_method(args.start_method)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "     \n",
    "    accelerator = accelerate.Accelerator()\n",
    "    device = accelerator.device\n",
    "    print('Using device:', device, flush=True)\n",
    "\n",
    "    aa_model = AudioAlgebra(args, device)\n",
    "\n",
    "    accelerator.print('Parameters:', blocks_utils.n_params(diffusion_model))\n",
    "\n",
    "    # If logging to wandb, initialize the run\n",
    "    use_wandb = accelerator.is_main_process and args.name\n",
    "    if use_wandb:\n",
    "        import wandb\n",
    "        config = vars(args)\n",
    "        config['params'] = utils.n_params(diffusion_model)\n",
    "        wandb.init(project=args.name, config=config, save_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cf199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed if listed in console_scripts in settings.ini\n",
    "#if __name__ == '__main__':\n",
    "#    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
