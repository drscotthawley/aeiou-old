{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp icebox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963eebd",
   "metadata": {},
   "source": [
    "# icebox\n",
    "> Routines for working with frozen jukebox embeddings\n",
    "\n",
    "Combination of TagBox repo by Ethan Manilow et al plus additions/modifications by Scott Hawley.\n",
    "\n",
    "This can be used as a library to be called from elsewhere, or as its own standalone script (mostly for testing and evaluation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ba33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import torch \n",
    "from torch import nn \n",
    "from torch import multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn import functional as F\n",
    "import torchaudio\n",
    "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
    "from jukebox.hparams import Hyperparams, setup_hparams\n",
    "import os\n",
    "import accelerate\n",
    "from shazbot.core import get_accel_config, HostPrinter\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866ac21",
   "metadata": {},
   "source": [
    "## TagBox utils\n",
    "\n",
    "Utilities from Ethan Manilows's TagBox: https://github.com/ethman/tagbox, slightly modified by Scott H. Hawley @drscotthawley\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffca9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "#JUKEBOX_SAMPLE_RATE = 44100  # ethan's original\n",
    "JUKEBOX_SAMPLE_RATE = None\n",
    "\n",
    "def init_jukebox_sample_rate(\n",
    "    sr=44100  # sample rate in Hz. OpenAI's pretrained Jukebox weights are for 44100\n",
    "    ): \n",
    "    \"SHH added this util to preserve rest of code minimall-modified\"\n",
    "    global JUKEBOX_SAMPLE_RATE\n",
    "    JUKEBOX_SAMPLE_RATE = sr\n",
    "    return\n",
    "\n",
    "def stereo(signal):\n",
    "    signal_shape = signal.shape\n",
    "    if len(signal_shape) == 1: # s -> 2, s\n",
    "        signal = signal.unsqueeze(0).repeat(2, 1)\n",
    "    elif len(signal_shape) == 2:\n",
    "        if signal_shape[0] == 1: #1, s -> 2, s\n",
    "            signal = signal.repeat(2, 1)\n",
    "        elif signal_shape[0] > 2: #?, s -> 2,s\n",
    "            signal = signal[:2, :]  \n",
    "    return signal \n",
    "\n",
    "def audio_for_jbx(audio, trunc_sec=None, device=None):\n",
    "    \"\"\"Readies an audio TENSOR for Jukebox.\"\"\"\n",
    "    if audio.ndim == 1:\n",
    "        audio = audio[None]\n",
    "        audio = audio.mean(axis=0)\n",
    "    #print(\"1 audio.shape = \",audio.shape)\n",
    "\n",
    "    # normalize audio\n",
    "    norm_factor = torch.abs(audio).max()\n",
    "    if norm_factor > 0:\n",
    "        audio /= norm_factor\n",
    "\n",
    "    if trunc_sec is not None:  # truncate sequence\n",
    "        audio = audio[: int(JUKEBOX_SAMPLE_RATE * trunc_sec)]\n",
    "\n",
    "    audio = torch.unsqueeze(audio, 0)  # batch dimension\n",
    "    audio = torch.unsqueeze(audio, dim=-1)  # another dimension ?\n",
    "    return audio\n",
    "\n",
    "\n",
    "def load_audio_for_jbx(path, offset=0.0, dur=None, trunc_sec=None, device=None):\n",
    "    \"\"\"Loads a path for use with Jukebox.\"\"\"\n",
    "    audio, sr = librosa.load(path, sr=None, offset=offset, duration=dur)\n",
    "\n",
    "    if JUKEBOX_SAMPLE_RATE is None: init_jukebox_sample_rate()\n",
    "\n",
    "    if sr != JUKEBOX_SAMPLE_RATE:\n",
    "        audio = librosa.resample(audio, sr, JUKEBOX_SAMPLE_RATE)\n",
    "    audio = torch.from_numpy(audio)\n",
    "    #print(\"0, audio.shape = \",audio.shape)\n",
    "    return audio_for_jbx(audio, trunc_sec, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870d4dd",
   "metadata": {},
   "source": [
    "## Icebox Encoder\n",
    "frozen Jukebox encoder for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb9a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IceBoxModel(nn.Module):\n",
    "    def __init__(self, global_args, device, port=9500):\n",
    "        super().__init__()\n",
    "\n",
    "        n_io_channels = 2\n",
    "        n_feature_channels = 8\n",
    "\n",
    "        # for making Jukebox work with multi-GPU runs\n",
    "        rank = global_args.rank\n",
    "        #local_rank, device = int(os.getenv('RANK')), int(os.getenv('LOCAL_RANK')), device\n",
    "\n",
    "        # torch.distributed info set at top-level training script\n",
    "        #dist_url = f\"tcp://127.0.0.1:{port}\"  # Note port may differ on different machines\n",
    "        #dist.init_process_group(backend=\"nccl\")\n",
    "\n",
    "        self.hps = Hyperparams()\n",
    "        assert global_args.sample_rate == 44100, \"Jukebox was pretrained at 44100 Hz.\"\n",
    "        self.hps.sr = global_args.sample_rate #44100\n",
    "        self.hps.levels = 3\n",
    "        self.hps.hop_fraction = [.5,.5,.125]\n",
    "\n",
    "        vqvae = \"vqvae\"\n",
    "        self.vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
    "        for param in self.vqvae.parameters():  # FREEZE IT.  \"IceBox\"\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.dummy = nn.Linear(1,1) # just to allow DistributedDataParallel\n",
    "\n",
    "        self.encoder = self.vqvae.encode\n",
    "        self.decoder = self.vqvae.decode\n",
    "\n",
    "        latent_dim = 64 # global_args.latent_dim. Jukebox is 64\n",
    "        io_channels = 2#1 # 2.  Jukebox is mono but we decode in stereo\n",
    " \n",
    "    def encode(self, *args, **kwargs):\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        return self.decoder(*args, **kwargs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def batch_it_crazy(x, win_len):\n",
    "    \"(pun intended) Chop up long sequence into a batch of win_len windows\"\n",
    "    x_len = x.size()[-1]\n",
    "    n_windows = (x_len // win_len) + 1\n",
    "    pad_amt = win_len * n_windows - x_len  # pad end w. zeros to make lengths even when split\n",
    "    xpad = F.pad(x, (0, pad_amt))\n",
    "    return rearrange(xpad, 'd (b n) -> b d n', n=win_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da5eef",
   "metadata": {},
   "source": [
    "## Main execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def main():\n",
    "    #from dotmap import DotMap  # only used for setting some args\n",
    "    from prefigure.prefigure import get_all_args, push_wandb_config\n",
    "\n",
    "    args = get_all_args()\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    try:\n",
    "        mp.set_start_method(args.start_method)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "    accelerator = accelerate.Accelerator()\n",
    "    device = accelerator.device\n",
    "    hprint = HostPrinter(accelerator)\n",
    "    hprint(f\"device = {device}\")\n",
    "    hprint(f\"accelerator = {accelerator}\")\n",
    "    ac = get_accel_config()\n",
    "    hprint(f\"ac = {ac}\")\n",
    "    port = ac['main_process_port']\n",
    "    #args = DotMap()\n",
    "    args.sample_rate = 44100\n",
    "    args.rank = ac['machine_rank']\n",
    "    os.environ[\"RANK\"] = str(args.rank)\n",
    "    if device != 'cpu':\n",
    "        icebox = IceBoxModel(args, device, port=port)\n",
    "        hprint(\"icebox config finished!\")\n",
    "    else:\n",
    "        print(\"can't start up icebox because no GPUs are available.\")\n",
    "\n",
    "    icebox = accelerator.prepare(icebox)\n",
    "\n",
    "    hprint(f\"Loading audio\")\n",
    "    input_filename = 'test_audio.wav'\n",
    "    input_audio = load_audio_for_jbx(input_filename).to(device)\n",
    "    #demo_reals = batch_it_crazy(input_audio, args.sample_size)\n",
    "\n",
    "\n",
    "    hprint(f\"Encoding audio\")\n",
    "    with torch.cuda.amp.autocast():\n",
    "        zs = accelerator.unwrap_model(icebox).encode(input_audio)\n",
    "\n",
    "    hprint(f\"Decoding audio\")\n",
    "    decoded = accelerator.unwrap_model(icebox).decode(zs).transpose(-2, -1)\n",
    "    hprint(f\"1 decoded.shape = {decoded.shape}\")\n",
    "    decoded = torch.squeeze(decoded, dim=0).cpu()\n",
    "    hprint(f\"2 decoded.shape = {decoded.shape}\")\n",
    "    outfilename = 'test_audio_out.wav'\n",
    "\n",
    "    hprint(f\"Saving output audio {outfilename}...\")\n",
    "    torchaudio.save(outfilename, decoded, args.sample_rate)\n",
    "\n",
    "    hprint(\"Finished!\")\n",
    "    \n",
    "if __name__ == '__main__':  # often this will only be called for testing\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae18e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('shazbot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a268e5e525fbd2c0f079ab7833a3344ce441000311f9c0688b8e579883100bc7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
