{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e44029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e6686d",
   "metadata": {},
   "source": [
    "# viz\n",
    "\n",
    "> Vizualization routines\n",
    "\n",
    "Pretty much an exact dupe of https://github.com/zqevans/audio-diffusion/blob/main/viz/viz.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794a4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "\n",
    "import math\n",
    "from pathlib import Path\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.figure import Figure\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.nn import functional as F\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import librosa \n",
    "from einops import rearrange\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def embeddings_table(tokens):\n",
    "    \"make a table of embeddings for use with wandb\"\n",
    "    features, labels = [], []\n",
    "    embeddings = rearrange(tokens, 'b d n -> b n d') # each demo sample is n vectors in d-dim space\n",
    "    for i in range(embeddings.size()[0]):  # nested for's are slow but sure ;-) \n",
    "        for j in range(embeddings.size()[1]):\n",
    "            features.append(embeddings[i,j].detach().cpu().numpy())\n",
    "            labels.append([f'demo{i}'])    # labels does the grouping / color for each point\n",
    "    features = np.array(features)\n",
    "    #print(\"\\nfeatures.shape = \",features.shape)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    cols = [f\"dim_{i}\" for i in range(features.shape[1])]\n",
    "    df   = pd.DataFrame(features, columns=cols)\n",
    "    df['LABEL'] = labels\n",
    "    return wandb.Table(columns=df.columns.to_list(), data=df.values)\n",
    "\n",
    "\n",
    "def proj_pca(tokens, proj_dims=3):\n",
    "    \"this projects via PCA, grabbing the first _3_ dimensions\"\n",
    "    A = rearrange(tokens, 'b d n -> (b n) d') # put all the vectors into the same d-dim space\n",
    "    if A.shape[-1] > proj_dims: \n",
    "        k = proj_dims\n",
    "        (U, S, V) = torch.pca_lowrank(A)\n",
    "        proj_data = torch.matmul(A, V[:, :k])  # this is the actual PCA projection step\n",
    "    else:\n",
    "        proj_data = A\n",
    "    return torch.reshape(proj_data, (tokens.size()[0], -1, proj_dims)) # put it in shape [batch, n, 3]\n",
    "\n",
    "\n",
    "def pca_point_cloud(tokens, color_scheme='batch'):\n",
    "    \"produces a 3D wandb point cloud of the tokens using PCA. tokens has shape (b, d, n)\"\n",
    "    data = proj_pca(tokens).cpu().numpy()\n",
    "    points = []\n",
    "    if color_scheme=='batch':\n",
    "        cmap, norm = cm.tab20, Normalize(vmin=0, vmax=data.shape[0])\n",
    "    else: \n",
    "        cmap, norm = cm.viridis, Normalize(vmin=0, vmax=data.shape[1])\n",
    "    print(\"   pca_point_cloud: data.shape = \",data.shape)\n",
    "    for bi in range(data.shape[0]):  # batch index\n",
    "        if color_scheme=='batch': [r, g, b, _] = [int(255*x) for x in cmap(norm(bi))] \n",
    "        for n in range(data.shape[1]):\n",
    "            if color_scheme!='batch': [r, g, b, _] = [int(255*x) for x in cmap(norm(n))] \n",
    "            #print(f\"  {data[bi,n,0]}, {data[bi,n,1]}, {data[bi,n,2]}, {r}, {g}, {b}\")\n",
    "            points.append([data[bi,n,0], data[bi,n,1], data[bi,n,2], r, g, b])\n",
    "\n",
    "    point_cloud = np.array(points)\n",
    "    print(\"   pca_point_cloud: point_cloud.shape = \",point_cloud.shape)\n",
    "    return wandb.Object3D(point_cloud)\n",
    "\n",
    "\n",
    "def spectrogram_image(spec, title=None, ylabel='freq_bin', aspect='auto', xmax=None, db_range=[-60,20]):\n",
    "    \"\"\"\n",
    "    # cf. https://pytorch.org/tutorials/beginner/audio_feature_extractions_tutorial.html\n",
    "\n",
    "    \"\"\"\n",
    "    fig = Figure(figsize=(5, 4), dpi=100)\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    axs = fig.add_subplot()\n",
    "    axs.set_title(title or 'Spectrogram (dB)')\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel('frame')\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin='lower', aspect=aspect, vmin=db_range[0], vmax=db_range[1])\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    canvas.draw()\n",
    "    rgba = np.asarray(canvas.buffer_rgba())\n",
    "    return Image.fromarray(rgba)\n",
    "\n",
    "def print_stats(waveform, sample_rate=None, src=None, print=print):\n",
    "    if src:\n",
    "        print(f\"-\" * 10)\n",
    "        print(f\"Source: {src}\")\n",
    "        print(f\"-\" * 10)\n",
    "    if sample_rate:\n",
    "        print(f\"Sample Rate: {sample_rate}\")\n",
    "    print(f\"Shape: {tuple(waveform.shape)}\")\n",
    "    print(f\"Dtype: {waveform.dtype}\")\n",
    "    print(f\" - Max:     {waveform.max().item():6.3f}\")\n",
    "    print(f\" - Min:     {waveform.min().item():6.3f}\")\n",
    "    print(f\" - Mean:    {waveform.mean().item():6.3f}\")\n",
    "    print(f\" - Std Dev: {waveform.std().item():6.3f}\")\n",
    "    print('')\n",
    "    print(f\"{waveform}\")\n",
    "    print('')\n",
    "\n",
    "def audio_spectrogram_image(waveform, power=2.0, sample_rate=48000, print=print, db_range=[-60,20]):\n",
    "    \"\"\"\n",
    "    # cf. https://pytorch.org/tutorials/beginner/audio_feature_extractions_tutorial.html\n",
    "    \"\"\"\n",
    "    n_fft = 1024\n",
    "    win_length = None\n",
    "    hop_length = n_fft//2 # 512\n",
    "    n_mels = 128\n",
    "\n",
    "    print(f\"waveform.shape = {waveform.shape}\")\n",
    "\n",
    "    mel_spectrogram_op = T.MelSpectrogram(\n",
    "        sample_rate=sample_rate, n_fft=n_fft, win_length=win_length, \n",
    "        hop_length=hop_length, center=True, pad_mode=\"reflect\", power=power, \n",
    "        norm='slaney', onesided=True, n_mels=n_mels, mel_scale=\"htk\")\n",
    "\n",
    "    melspec = mel_spectrogram_op(waveform.float())\n",
    "    print_stats(melspec, print=print)\n",
    "    print(f\"torch.max(melspec) = {torch.max(melspec)}\")\n",
    "    print(f\"melspec.shape = {melspec.shape}\")\n",
    "    melspec = melspec[0] # TODO: only left channel for now\n",
    "    return spectrogram_image(melspec, title=\"MelSpectrogram\", ylabel='mel bins (log freq)', db_range=db_range)\n",
    "\n",
    "\n",
    "def tokens_spectrogram_image(tokens, aspect='auto', title='Embeddings', ylabel='index'):\n",
    "    embeddings = rearrange(tokens, 'b d n -> (b n) d') \n",
    "    print(f\"tokens_spectrogram_image: embeddings.shape = \",embeddings.shape)\n",
    "    fig = Figure(figsize=(10, 4), dpi=100)\n",
    "    canvas = FigureCanvasAgg(fig)\n",
    "    axs = fig.add_subplot()\n",
    "    axs.set_title(title or 'Embeddings')\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel('time frame')\n",
    "    im = axs.imshow(embeddings.cpu().numpy().T, origin='lower', aspect=aspect, interpolation='none') #.T because numpy is x/y 'backwards'\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    canvas.draw()\n",
    "    rgba = np.asarray(canvas.buffer_rgba())\n",
    "    return Image.fromarray(rgba)\n",
    "\n",
    "\n",
    "def plot_jukebox_embeddings(zs, aspect='auto'):\n",
    "    fig, ax = plt.subplots(nrows=len(zs))\n",
    "    for i, z in enumerate(zs):\n",
    "        #z = torch.squeeze(z)\n",
    "        z = z.cpu().numpy()\n",
    "        x = np.arange(z.shape[-1])\n",
    "        im = ax[i].imshow(z, origin='lower', aspect=aspect, interpolation='none')\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.ylabel(\"emb (top=fine, bottom=coarse)\")\n",
    "    return {\"chart\": plt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80071d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
